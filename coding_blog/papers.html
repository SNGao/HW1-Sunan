<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>arXiv Paper Feed | Coding Blog</title>
    <link rel="stylesheet" href="css/style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Fira+Code:wght@400;500&display=swap" rel="stylesheet">
    <style>
        .papers-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 100px 20px 40px;
        }
        .papers-header {
            text-align: center;
            margin-bottom: 40px;
        }
        .papers-header h1 {
            font-size: 2.5rem;
            margin-bottom: 10px;
            background: linear-gradient(135deg, var(--primary), var(--secondary));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        .update-info {
            color: #cbd5e1;
            font-size: 0.9rem;
            margin-bottom: 8px;
        }
        .auto-update-info {
            color: #22c55e;
            font-size: 0.85rem;
            margin-bottom: 15px;
        }
        .config-hint {
            color: #94a3b8;
            font-size: 0.8rem;
            margin-bottom: 10px;
        }
        .config-hint code {
            background: #334155;
            padding: 2px 6px;
            border-radius: 4px;
            font-family: var(--font-code);
            color: #f472b6;
        }
        .search-box {
            max-width: 500px;
            margin: 20px auto;
        }
        .search-box input {
            width: 100%;
            padding: 12px 20px;
            border: 2px solid var(--border);
            border-radius: 25px;
            background: var(--card-bg);
            color: var(--text-primary);
            font-size: 1rem;
            outline: none;
            transition: border-color 0.3s;
        }
        .search-box input:focus {
            border-color: var(--primary);
        }
        .search-box input::placeholder {
            color: var(--text-muted);
        }
        .papers-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(350px, 1fr));
            gap: 25px;
        }
        .paper-card {
            background: var(--card-bg);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 25px;
            transition: all 0.3s ease;
        }
        .paper-card:hover {
            border-color: var(--primary);
            transform: translateY(-3px);
            box-shadow: 0 10px 30px rgba(236, 72, 153, 0.15);
        }
        .paper-card.hidden {
            display: none;
        }
        .paper-title {
            font-size: 1.1rem;
            font-weight: 600;
            color: var(--text-primary);
            margin-bottom: 10px;
            line-height: 1.4;
        }
        .paper-title a {
            color: inherit;
            text-decoration: none;
            transition: color 0.3s;
        }
        .paper-title a:hover {
            color: var(--primary);
        }
        .paper-meta {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            margin-bottom: 12px;
        }
        .paper-date {
            background: var(--primary);
            color: white;
            padding: 4px 10px;
            border-radius: 15px;
            font-size: 0.75rem;
            font-weight: 500;
        }
        .paper-category {
            background: #334155;
            color: #e2e8f0;
            padding: 4px 10px;
            border-radius: 15px;
            font-size: 0.75rem;
        }
        .paper-authors {
            color: #cbd5e1;
            font-size: 0.9rem;
            margin-bottom: 12px;
            line-height: 1.5;
        }
        .paper-abstract {
            color: #94a3b8;
            font-size: 0.9rem;
            line-height: 1.7;
            margin-bottom: 15px;
        }
        .paper-abstract.expanded {
            max-height: none;
        }
        .expand-btn {
            background: none;
            border: none;
            color: var(--primary);
            cursor: pointer;
            font-size: 0.85rem;
            padding: 0;
            margin-bottom: 15px;
        }
        .expand-btn:hover {
            text-decoration: underline;
        }
        .paper-actions {
            display: flex;
            gap: 10px;
        }
        .pdf-btn {
            display: inline-flex;
            align-items: center;
            gap: 6px;
            padding: 8px 16px;
            background: linear-gradient(135deg, var(--primary), var(--secondary));
            color: white;
            text-decoration: none;
            border-radius: 20px;
            font-size: 0.85rem;
            font-weight: 500;
            transition: all 0.3s;
        }
        .pdf-btn:hover {
            transform: scale(1.05);
            box-shadow: 0 5px 15px rgba(236, 72, 153, 0.3);
        }
        .arxiv-btn {
            display: inline-flex;
            align-items: center;
            gap: 6px;
            padding: 8px 16px;
            background: var(--surface);
            color: var(--text-primary);
            text-decoration: none;
            border-radius: 20px;
            font-size: 0.85rem;
            font-weight: 500;
            border: 1px solid var(--border);
            transition: all 0.3s;
        }
        .arxiv-btn:hover {
            border-color: var(--primary);
            color: var(--primary);
        }
        .no-results {
            text-align: center;
            padding: 60px 20px;
            color: var(--text-muted);
        }
        .no-results h3 {
            font-size: 1.5rem;
            margin-bottom: 10px;
            color: var(--text-secondary);
        }
        .keywords-info {
            background: #1e293b;
            padding: 20px;
            border-radius: 12px;
            margin-bottom: 30px;
            text-align: center;
            border: 1px solid #334155;
        }
        .keywords-info > span {
            color: #e2e8f0;
            font-size: 0.95rem;
            font-weight: 500;
        }
        .keyword-tag {
            display: inline-block;
            background: linear-gradient(135deg, #6366f1, #ec4899);
            color: #ffffff;
            padding: 6px 14px;
            border-radius: 20px;
            font-size: 0.85rem;
            font-weight: 600;
            margin: 4px;
            text-shadow: 0 1px 2px rgba(0,0,0,0.2);
        }
        .keyword-editor {
            margin-top: 15px;
            padding-top: 15px;
            border-top: 1px solid #334155;
        }
        .keyword-input-group {
            display: flex;
            gap: 10px;
            justify-content: center;
            flex-wrap: wrap;
            margin-top: 10px;
        }
        .keyword-input {
            padding: 10px 16px;
            border: 2px solid #334155;
            border-radius: 25px;
            background: #0f172a;
            color: #f8fafc;
            font-size: 0.9rem;
            width: 250px;
            outline: none;
            transition: border-color 0.3s;
        }
        .keyword-input:focus {
            border-color: #6366f1;
        }
        .keyword-input::placeholder {
            color: #64748b;
        }
        .fetch-btn {
            padding: 10px 24px;
            background: linear-gradient(135deg, #6366f1, #ec4899);
            color: white;
            border: none;
            border-radius: 25px;
            font-size: 0.9rem;
            font-weight: 600;
            cursor: pointer;
            transition: transform 0.2s, box-shadow 0.2s;
        }
        .fetch-btn:hover {
            transform: scale(1.05);
            box-shadow: 0 5px 20px rgba(99, 102, 241, 0.4);
        }
        .fetch-btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
        }
        .editor-hint {
            color: #94a3b8;
            font-size: 0.8rem;
            margin-top: 8px;
        }
        @media (max-width: 768px) {
            .papers-grid {
                grid-template-columns: 1fr;
            }
            .papers-header h1 {
                font-size: 1.8rem;
            }
        }
    </style>
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar">
        <div class="nav-container">
            <a href="index.html" class="nav-logo">
                <span class="logo-icon">ğŸ’»</span>
                <span class="logo-text">Coding Blog</span>
            </a>
            <ul class="nav-menu">
                <li><a href="index.html" class="nav-link">Home</a></li>
                <li><a href="index.html#projects" class="nav-link">Projects</a></li>
                <li><a href="papers.html" class="nav-link active">Papers</a></li>
                <li><a href="index.html#about" class="nav-link">About</a></li>
            </ul>
            <button class="nav-toggle" aria-label="Toggle navigation">
                <span></span>
                <span></span>
                <span></span>
            </button>
        </div>
    </nav>

    <div class="papers-container">
        <div class="papers-header">
            <h1>ğŸ“š arXiv Paper Feed</h1>
            <p class="update-info">Last updated: 2026-02-19 01:47:18 UTC</p>
            <p class="auto-update-info">â° Auto-updates daily at midnight UTC via GitHub Actions</p>
            <div class="keywords-info">
                <span>Current keywords: </span>
                <div id="currentKeywords">
                    <span class="keyword-tag">large language model</span><span class="keyword-tag">machine learning</span><span class="keyword-tag">biostatistics</span><span class="keyword-tag">deep learning</span>
                </div>
                <div class="keyword-editor">
                    <p class="editor-hint">ğŸ”„ Try different keywords (fetches live from arXiv):</p>
                    <div class="keyword-input-group">
                        <input type="text" id="customKeywords" class="keyword-input" 
                               placeholder="e.g., reinforcement learning, NLP" 
                               value="large language model, machine learning, biostatistics, deep learning">
                        <button onclick="fetchCustomPapers()" class="fetch-btn" id="fetchBtn">
                            Fetch Papers
                        </button>
                    </div>
                    <p class="editor-hint">Separate multiple keywords with commas</p>
                </div>
            </div>
            <div class="search-box">
                <input type="text" id="searchInput" placeholder="ğŸ” Filter papers by title, author, or abstract..." oninput="filterPapers()">
            </div>
        </div>

        <div class="papers-grid" id="papersGrid">

            <article class="paper-card" data-search="ensemble-size-dependence of deep-learning post-processing methods that minimize an (un)fair score: motivating examples and a proof-of-concept solution christopher david roberts fair scores reward ensemble forecast members that behave like samples from the same distribution as the verifying observations. they are therefore an attractive choice as loss functions to train data-driven ensemble forecasts or post-processing methods when large training ensembles are either unavailable or computationally prohibitive. the adjusted continuous ranked probability score (acrps) is fair and unbiased with respect to ensemble size, provided forecast members are exchangeable and interpretable as conditionally independent draws from an underlying predictive distribution. however, distribution-aware post-processing methods that introduce structural dependency between members can violate this assumption, rendering acrps unfair. we demonstrate this effect using two approaches designed to minimize the expected acrps of a finite ensemble: (1) a linear member-by-member calibration, which couples members through a common dependency on the sample ensemble mean, and (2) a deep-learning method, which couples members via transformer self-attention across the ensemble dimension. in both cases, the results are sensitive to ensemble size and apparent gains in acrps can correspond to systematic unreliability characterized by over-dispersion. we introduce trajectory transformers as a proof-of-concept that ensemble-size independence can be achieved. this approach is an adaptation of the post-processing ensembles with transformers (poet) framework and applies self-attention over lead time while preserving the conditional independence required by acrps. when applied to weekly mean $t_{2m}$ forecasts from the ecmwf subseasonal forecasting system, this approach successfully reduces systematic model biases whilst also improving or maintaining forecast reliability regardless of the ensemble size used in training (3 vs 9 members) or real-time forecasts (9 vs 100 members).">
                <h2 class="paper-title">
                    <a href="https://arxiv.org/abs/2602.15830v1" target="_blank" rel="noopener">Ensemble-size-dependence of deep-learning post-processing methods that minimize an (un)fair score: motivating examples and a proof-of-concept solution</a>
                </h2>
                <div class="paper-meta">
                    <span class="paper-date">ğŸ“… 2026-02-17</span>
                    <span class="paper-category">physics.ao-ph</span><span class="paper-category">cs.LG</span>
                </div>
                <p class="paper-authors">Christopher David Roberts</p>
                <p class="paper-abstract" id="abstract-0">Fair scores reward ensemble forecast members that behave like samples from the same distribution as the verifying observations. They are therefore an attractive choice as loss functions to train...</p>
                <button class="expand-btn" onclick="toggleAbstract(0, 'Fair scores reward ensemble forecast members that behave like samples from the same distribution as the verifying observations. They are therefore an attractive choice as loss functions to train data-driven ensemble forecasts or post-processing methods when large training ensembles are either unavailable or computationally prohibitive. The adjusted continuous ranked probability score (aCRPS) is fair and unbiased with respect to ensemble size, provided forecast members are exchangeable and interpretable as conditionally independent draws from an underlying predictive distribution. However, distribution-aware post-processing methods that introduce structural dependency between members can violate this assumption, rendering aCRPS unfair. We demonstrate this effect using two approaches designed to minimize the expected aCRPS of a finite ensemble: (1) a linear member-by-member calibration, which couples members through a common dependency on the sample ensemble mean, and (2) a deep-learning method, which couples members via transformer self-attention across the ensemble dimension. In both cases, the results are sensitive to ensemble size and apparent gains in aCRPS can correspond to systematic unreliability characterized by over-dispersion. We introduce trajectory transformers as a proof-of-concept that ensemble-size independence can be achieved. This approach is an adaptation of the Post-processing Ensembles with Transformers (PoET) framework and applies self-attention over lead time while preserving the conditional independence required by aCRPS. When applied to weekly mean $T_{2m}$ forecasts from the ECMWF subseasonal forecasting system, this approach successfully reduces systematic model biases whilst also improving or maintaining forecast reliability regardless of the ensemble size used in training (3 vs 9 members) or real-time forecasts (9 vs 100 members).', 'Fair scores reward ensemble forecast members that behave like samples from the same distribution as the verifying observations. They are therefore an attractive choice as loss functions to train...')" id="expand-btn-0">Show more â–¼</button>
                <div class="paper-actions">
                    <a href="https://arxiv.org/pdf/2602.15830v1" class="pdf-btn" target="_blank" rel="noopener">ğŸ“„ View PDF</a>
                    <a href="https://arxiv.org/abs/2602.15830v1" class="arxiv-btn" target="_blank" rel="noopener">ğŸ”— arXiv</a>
                </div>
            </article>

            <article class="paper-card" data-search="operationalising the superficial alignment hypothesis via task complexity tomÃ¡s vergara-browne darshan patil ivan titov siva reddy tiago pimentel marius mosbach the superficial alignment hypothesis (sah) posits that large language models learn most of their knowledge during pre-training, and that post-training merely surfaces this knowledge. the sah, however, lacks a precise definition, which has led to (i) different and seemingly orthogonal arguments supporting it, and (ii) important critiques to it. we propose a new metric called task complexity: the length of the shortest program that achieves a target performance on a task. in this framework, the sah simply claims that pre-trained models drastically reduce the complexity of achieving high performance on many tasks. our definition unifies prior arguments supporting the sah, interpreting them as different strategies to find such short programs. experimentally, we estimate the task complexity of mathematical reasoning, machine translation, and instruction following; we then show that these complexities can be remarkably low when conditioned on a pre-trained model. further, we find that pre-training enables access to strong performances on our tasks, but it can require programs of gigabytes of length to access them. post-training, on the other hand, collapses the complexity of reaching this same performance by several orders of magnitude. overall, our results highlight that task adaptation often requires surprisingly little information -- often just a few kilobytes.">
                <h2 class="paper-title">
                    <a href="https://arxiv.org/abs/2602.15829v1" target="_blank" rel="noopener">Operationalising the Superficial Alignment Hypothesis via Task Complexity</a>
                </h2>
                <div class="paper-meta">
                    <span class="paper-date">ğŸ“… 2026-02-17</span>
                    <span class="paper-category">cs.LG</span>
                </div>
                <p class="paper-authors">TomÃ¡s Vergara-Browne, Darshan Patil, Ivan Titov, Siva Reddy, Tiago Pimentel <em>(+1 more)</em></p>
                <p class="paper-abstract" id="abstract-1">The superficial alignment hypothesis (SAH) posits that large language models learn most of their knowledge during pre-training, and that post-training merely surfaces this knowledge. The SAH,...</p>
                <button class="expand-btn" onclick="toggleAbstract(1, 'The superficial alignment hypothesis (SAH) posits that large language models learn most of their knowledge during pre-training, and that post-training merely surfaces this knowledge. The SAH, however, lacks a precise definition, which has led to (i) different and seemingly orthogonal arguments supporting it, and (ii) important critiques to it. We propose a new metric called task complexity: the length of the shortest program that achieves a target performance on a task. In this framework, the SAH simply claims that pre-trained models drastically reduce the complexity of achieving high performance on many tasks. Our definition unifies prior arguments supporting the SAH, interpreting them as different strategies to find such short programs. Experimentally, we estimate the task complexity of mathematical reasoning, machine translation, and instruction following; we then show that these complexities can be remarkably low when conditioned on a pre-trained model. Further, we find that pre-training enables access to strong performances on our tasks, but it can require programs of gigabytes of length to access them. Post-training, on the other hand, collapses the complexity of reaching this same performance by several orders of magnitude. Overall, our results highlight that task adaptation often requires surprisingly little information -- often just a few kilobytes.', 'The superficial alignment hypothesis (SAH) posits that large language models learn most of their knowledge during pre-training, and that post-training merely surfaces this knowledge. The SAH,...')" id="expand-btn-1">Show more â–¼</button>
                <div class="paper-actions">
                    <a href="https://arxiv.org/pdf/2602.15829v1" class="pdf-btn" target="_blank" rel="noopener">ğŸ“„ View PDF</a>
                    <a href="https://arxiv.org/abs/2602.15829v1" class="arxiv-btn" target="_blank" rel="noopener">ğŸ”— arXiv</a>
                </div>
            </article>

            <article class="paper-card" data-search="dex4d: task-agnostic point track policy for sim-to-real dexterous manipulation yuxuan kuang sungjae park katerina fragkiadaki shubham tulsiani learning generalist policies capable of accomplishing a plethora of everyday tasks remains an open challenge in dexterous manipulation. in particular, collecting large-scale manipulation data via real-world teleoperation is expensive and difficult to scale. while learning in simulation provides a feasible alternative, designing multiple task-specific environments and rewards for training is similarly challenging. we propose dex4d, a framework that instead leverages simulation for learning task-agnostic dexterous skills that can be flexibly recomposed to perform diverse real-world manipulation tasks. specifically, dex4d learns a domain-agnostic 3d point track conditioned policy capable of manipulating any object to any desired pose. we train this &#x27;anypose-to-anypose&#x27; policy in simulation across thousands of objects with diverse pose configurations, covering a broad space of robot-object interactions that can be composed at test time. at deployment, this policy can be zero-shot transferred to real-world tasks without finetuning, simply by prompting it with desired object-centric point tracks extracted from generated videos. during execution, dex4d uses online point tracking for closed-loop perception and control. extensive experiments in simulation and on real robots show that our method enables zero-shot deployment for diverse dexterous manipulation tasks and yields consistent improvements over prior baselines. furthermore, we demonstrate strong generalization to novel objects, scene layouts, backgrounds, and trajectories, highlighting the robustness and scalability of the proposed framework.">
                <h2 class="paper-title">
                    <a href="https://arxiv.org/abs/2602.15828v1" target="_blank" rel="noopener">Dex4D: Task-Agnostic Point Track Policy for Sim-to-Real Dexterous Manipulation</a>
                </h2>
                <div class="paper-meta">
                    <span class="paper-date">ğŸ“… 2026-02-17</span>
                    <span class="paper-category">cs.RO</span><span class="paper-category">cs.CV</span><span class="paper-category">cs.LG</span>
                </div>
                <p class="paper-authors">Yuxuan Kuang, Sungjae Park, Katerina Fragkiadaki, Shubham Tulsiani</p>
                <p class="paper-abstract" id="abstract-2">Learning generalist policies capable of accomplishing a plethora of everyday tasks remains an open challenge in dexterous manipulation. In particular, collecting large-scale manipulation data via...</p>
                <button class="expand-btn" onclick="toggleAbstract(2, 'Learning generalist policies capable of accomplishing a plethora of everyday tasks remains an open challenge in dexterous manipulation. In particular, collecting large-scale manipulation data via real-world teleoperation is expensive and difficult to scale. While learning in simulation provides a feasible alternative, designing multiple task-specific environments and rewards for training is similarly challenging. We propose Dex4D, a framework that instead leverages simulation for learning task-agnostic dexterous skills that can be flexibly recomposed to perform diverse real-world manipulation tasks. Specifically, Dex4D learns a domain-agnostic 3D point track conditioned policy capable of manipulating any object to any desired pose. We train this &#x27;Anypose-to-Anypose&#x27; policy in simulation across thousands of objects with diverse pose configurations, covering a broad space of robot-object interactions that can be composed at test time. At deployment, this policy can be zero-shot transferred to real-world tasks without finetuning, simply by prompting it with desired object-centric point tracks extracted from generated videos. During execution, Dex4D uses online point tracking for closed-loop perception and control. Extensive experiments in simulation and on real robots show that our method enables zero-shot deployment for diverse dexterous manipulation tasks and yields consistent improvements over prior baselines. Furthermore, we demonstrate strong generalization to novel objects, scene layouts, backgrounds, and trajectories, highlighting the robustness and scalability of the proposed framework.', 'Learning generalist policies capable of accomplishing a plethora of everyday tasks remains an open challenge in dexterous manipulation. In particular, collecting large-scale manipulation data via...')" id="expand-btn-2">Show more â–¼</button>
                <div class="paper-actions">
                    <a href="https://arxiv.org/pdf/2602.15828v1" class="pdf-btn" target="_blank" rel="noopener">ğŸ“„ View PDF</a>
                    <a href="https://arxiv.org/abs/2602.15828v1" class="arxiv-btn" target="_blank" rel="noopener">ğŸ”— arXiv</a>
                </div>
            </article>

            <article class="paper-card" data-search="perceptive humanoid parkour: chaining dynamic human skills via motion matching zhen wu xiaoyu huang lujie yang yuanhang zhang koushil sreenath xi chen pieter abbeel rocky duan angjoo kanazawa carmelo sferrazza guanya shi c. karen liu while recent advances in humanoid locomotion have achieved stable walking on varied terrains, capturing the agility and adaptivity of highly dynamic human motions remains an open challenge. in particular, agile parkour in complex environments demands not only low-level robustness, but also human-like motion expressiveness, long-horizon skill composition, and perception-driven decision-making. in this paper, we present perceptive humanoid parkour (php), a modular framework that enables humanoid robots to autonomously perform long-horizon, vision-based parkour across challenging obstacle courses. our approach first leverages motion matching, formulated as nearest-neighbor search in a feature space, to compose retargeted atomic human skills into long-horizon kinematic trajectories. this framework enables the flexible composition and smooth transition of complex skill chains while preserving the elegance and fluidity of dynamic human motions. next, we train motion-tracking reinforcement learning (rl) expert policies for these composed motions, and distill them into a single depth-based, multi-skill student policy, using a combination of dagger and rl. crucially, the combination of perception and skill composition enables autonomous, context-aware decision-making: using only onboard depth sensing and a discrete 2d velocity command, the robot selects and executes whether to step over, climb onto, vault or roll off obstacles of varying geometries and heights. we validate our framework with extensive real-world experiments on a unitree g1 humanoid robot, demonstrating highly dynamic parkour skills such as climbing tall obstacles up to 1.25m (96% robot height), as well as long-horizon multi-obstacle traversal with closed-loop adaptation to real-time obstacle perturbations.">
                <h2 class="paper-title">
                    <a href="https://arxiv.org/abs/2602.15827v1" target="_blank" rel="noopener">Perceptive Humanoid Parkour: Chaining Dynamic Human Skills via Motion Matching</a>
                </h2>
                <div class="paper-meta">
                    <span class="paper-date">ğŸ“… 2026-02-17</span>
                    <span class="paper-category">cs.RO</span><span class="paper-category">cs.AI</span><span class="paper-category">cs.LG</span>
                </div>
                <p class="paper-authors">Zhen Wu, Xiaoyu Huang, Lujie Yang, Yuanhang Zhang, Koushil Sreenath <em>(+7 more)</em></p>
                <p class="paper-abstract" id="abstract-3">While recent advances in humanoid locomotion have achieved stable walking on varied terrains, capturing the agility and adaptivity of highly dynamic human motions remains an open challenge. In...</p>
                <button class="expand-btn" onclick="toggleAbstract(3, 'While recent advances in humanoid locomotion have achieved stable walking on varied terrains, capturing the agility and adaptivity of highly dynamic human motions remains an open challenge. In particular, agile parkour in complex environments demands not only low-level robustness, but also human-like motion expressiveness, long-horizon skill composition, and perception-driven decision-making. In this paper, we present Perceptive Humanoid Parkour (PHP), a modular framework that enables humanoid robots to autonomously perform long-horizon, vision-based parkour across challenging obstacle courses. Our approach first leverages motion matching, formulated as nearest-neighbor search in a feature space, to compose retargeted atomic human skills into long-horizon kinematic trajectories. This framework enables the flexible composition and smooth transition of complex skill chains while preserving the elegance and fluidity of dynamic human motions. Next, we train motion-tracking reinforcement learning (RL) expert policies for these composed motions, and distill them into a single depth-based, multi-skill student policy, using a combination of DAgger and RL. Crucially, the combination of perception and skill composition enables autonomous, context-aware decision-making: using only onboard depth sensing and a discrete 2D velocity command, the robot selects and executes whether to step over, climb onto, vault or roll off obstacles of varying geometries and heights. We validate our framework with extensive real-world experiments on a Unitree G1 humanoid robot, demonstrating highly dynamic parkour skills such as climbing tall obstacles up to 1.25m (96% robot height), as well as long-horizon multi-obstacle traversal with closed-loop adaptation to real-time obstacle perturbations.', 'While recent advances in humanoid locomotion have achieved stable walking on varied terrains, capturing the agility and adaptivity of highly dynamic human motions remains an open challenge. In...')" id="expand-btn-3">Show more â–¼</button>
                <div class="paper-actions">
                    <a href="https://arxiv.org/pdf/2602.15827v1" class="pdf-btn" target="_blank" rel="noopener">ğŸ“„ View PDF</a>
                    <a href="https://arxiv.org/abs/2602.15827v1" class="arxiv-btn" target="_blank" rel="noopener">ğŸ”— arXiv</a>
                </div>
            </article>

            <article class="paper-card" data-search="crispedit: low-curvature projections for scalable non-destructive llm editing zarif ikram arad firouzkouhi stephen tu mahdi soltanolkotabi paria rashidinejad a central challenge in large language model (llm) editing is capability preservation: methods that successfully change targeted behavior can quietly game the editing proxy and corrupt general capabilities, producing degenerate behaviors reminiscent of proxy/reward hacking. we present crispedit, a scalable and principled second-order editing algorithm that treats capability preservation as an explicit constraint, unifying and generalizing several existing editing approaches. crispedit formulates editing as constrained optimization and enforces the constraint by projecting edit updates onto the low-curvature subspace of the capability-loss landscape. at the crux of crispedit is expressing capability constraint via bregman divergence, whose quadratic form yields the gauss-newton hessian exactly and even when the base model is not trained to convergence. we make this second-order procedure efficient at the llm scale using kronecker-factored approximate curvature (k-fac) and a novel matrix-free projector that exploits kronecker structure to avoid constructing massive projection matrices. across standard model-editing benchmarks, crispedit achieves high edit success while keeping capability degradation below 1% on average across datasets, significantly improving over prior editors.">
                <h2 class="paper-title">
                    <a href="https://arxiv.org/abs/2602.15823v1" target="_blank" rel="noopener">CrispEdit: Low-Curvature Projections for Scalable Non-Destructive LLM Editing</a>
                </h2>
                <div class="paper-meta">
                    <span class="paper-date">ğŸ“… 2026-02-17</span>
                    <span class="paper-category">cs.LG</span><span class="paper-category">cs.AI</span>
                </div>
                <p class="paper-authors">Zarif Ikram, Arad Firouzkouhi, Stephen Tu, Mahdi Soltanolkotabi, Paria Rashidinejad</p>
                <p class="paper-abstract" id="abstract-4">A central challenge in large language model (LLM) editing is capability preservation: methods that successfully change targeted behavior can quietly game the editing proxy and corrupt general...</p>
                <button class="expand-btn" onclick="toggleAbstract(4, 'A central challenge in large language model (LLM) editing is capability preservation: methods that successfully change targeted behavior can quietly game the editing proxy and corrupt general capabilities, producing degenerate behaviors reminiscent of proxy/reward hacking. We present CrispEdit, a scalable and principled second-order editing algorithm that treats capability preservation as an explicit constraint, unifying and generalizing several existing editing approaches. CrispEdit formulates editing as constrained optimization and enforces the constraint by projecting edit updates onto the low-curvature subspace of the capability-loss landscape. At the crux of CrispEdit is expressing capability constraint via Bregman divergence, whose quadratic form yields the Gauss-Newton Hessian exactly and even when the base model is not trained to convergence. We make this second-order procedure efficient at the LLM scale using Kronecker-factored approximate curvature (K-FAC) and a novel matrix-free projector that exploits Kronecker structure to avoid constructing massive projection matrices. Across standard model-editing benchmarks, CrispEdit achieves high edit success while keeping capability degradation below 1% on average across datasets, significantly improving over prior editors.', 'A central challenge in large language model (LLM) editing is capability preservation: methods that successfully change targeted behavior can quietly game the editing proxy and corrupt general...')" id="expand-btn-4">Show more â–¼</button>
                <div class="paper-actions">
                    <a href="https://arxiv.org/pdf/2602.15823v1" class="pdf-btn" target="_blank" rel="noopener">ğŸ“„ View PDF</a>
                    <a href="https://arxiv.org/abs/2602.15823v1" class="arxiv-btn" target="_blank" rel="noopener">ğŸ”— arXiv</a>
                </div>
            </article>

            <article class="paper-card" data-search="stabilizing test-time adaptation of high-dimensional simulation surrogates via d-optimal statistics anna zimmel paul setinek gianluca galletti johannes brandstetter werner zellinger machine learning surrogates are increasingly used in engineering to accelerate costly simulations, yet distribution shifts between training and deployment often cause severe performance degradation (e.g., unseen geometries or configurations). test-time adaptation (tta) can mitigate such shifts, but existing methods are largely developed for lower-dimensional classification with structured outputs and visually aligned input-output relationships, making them unstable for the high-dimensional, unstructured and regression problems common in simulation. we address this challenge by proposing a tta framework based on storing maximally informative (d-optimal) statistics, which jointly enables stable adaptation and principled parameter selection at test time. when applied to pretrained simulation surrogates, our method yields up to 7% out-of-distribution improvements at negligible computational cost. to the best of our knowledge, this is the first systematic demonstration of effective tta for high-dimensional simulation regression and generative design optimization, validated on the simshift and engibench benchmarks.">
                <h2 class="paper-title">
                    <a href="https://arxiv.org/abs/2602.15820v1" target="_blank" rel="noopener">Stabilizing Test-Time Adaptation of High-Dimensional Simulation Surrogates via D-Optimal Statistics</a>
                </h2>
                <div class="paper-meta">
                    <span class="paper-date">ğŸ“… 2026-02-17</span>
                    <span class="paper-category">cs.LG</span>
                </div>
                <p class="paper-authors">Anna Zimmel, Paul Setinek, Gianluca Galletti, Johannes Brandstetter, Werner Zellinger</p>
                <p class="paper-abstract" id="abstract-5">Machine learning surrogates are increasingly used in engineering to accelerate costly simulations, yet distribution shifts between training and deployment often cause severe performance degradation...</p>
                <button class="expand-btn" onclick="toggleAbstract(5, 'Machine learning surrogates are increasingly used in engineering to accelerate costly simulations, yet distribution shifts between training and deployment often cause severe performance degradation (e.g., unseen geometries or configurations). Test-Time Adaptation (TTA) can mitigate such shifts, but existing methods are largely developed for lower-dimensional classification with structured outputs and visually aligned input-output relationships, making them unstable for the high-dimensional, unstructured and regression problems common in simulation. We address this challenge by proposing a TTA framework based on storing maximally informative (D-optimal) statistics, which jointly enables stable adaptation and principled parameter selection at test time. When applied to pretrained simulation surrogates, our method yields up to 7% out-of-distribution improvements at negligible computational cost. To the best of our knowledge, this is the first systematic demonstration of effective TTA for high-dimensional simulation regression and generative design optimization, validated on the SIMSHIFT and EngiBench benchmarks.', 'Machine learning surrogates are increasingly used in engineering to accelerate costly simulations, yet distribution shifts between training and deployment often cause severe performance degradation...')" id="expand-btn-5">Show more â–¼</button>
                <div class="paper-actions">
                    <a href="https://arxiv.org/pdf/2602.15820v1" class="pdf-btn" target="_blank" rel="noopener">ğŸ“„ View PDF</a>
                    <a href="https://arxiv.org/abs/2602.15820v1" class="arxiv-btn" target="_blank" rel="noopener">ğŸ”— arXiv</a>
                </div>
            </article>

            <article class="paper-card" data-search="videosketcher: video models prior enable versatile sequential sketch generation hui ren yuval alaluf omer bar tal alexander schwing antonio torralba yael vinker sketching is inherently a sequential process, in which strokes are drawn in a meaningful order to explore and refine ideas. however, most generative models treat sketches as static images, overlooking the temporal structure that underlies creative drawing. we present a data-efficient approach for sequential sketch generation that adapts pretrained text-to-video diffusion models to generate sketching processes. our key insight is that large language models and video diffusion models offer complementary strengths for this task: llms provide semantic planning and stroke ordering, while video diffusion models serve as strong renderers that produce high-quality, temporally coherent visuals. we leverage this by representing sketches as short videos in which strokes are progressively drawn on a blank canvas, guided by text-specified ordering instructions. we introduce a two-stage fine-tuning strategy that decouples the learning of stroke ordering from the learning of sketch appearance. stroke ordering is learned using synthetic shape compositions with controlled temporal structure, while visual appearance is distilled from as few as seven manually authored sketching processes that capture both global drawing order and the continuous formation of individual strokes. despite the extremely limited amount of human-drawn sketch data, our method generates high-quality sequential sketches that closely follow text-specified orderings while exhibiting rich visual detail. we further demonstrate the flexibility of our approach through extensions such as brush style conditioning and autoregressive sketch generation, enabling additional controllability and interactive, collaborative drawing.">
                <h2 class="paper-title">
                    <a href="https://arxiv.org/abs/2602.15819v1" target="_blank" rel="noopener">VideoSketcher: Video Models Prior Enable Versatile Sequential Sketch Generation</a>
                </h2>
                <div class="paper-meta">
                    <span class="paper-date">ğŸ“… 2026-02-17</span>
                    <span class="paper-category">cs.CV</span>
                </div>
                <p class="paper-authors">Hui Ren, Yuval Alaluf, Omer Bar Tal, Alexander Schwing, Antonio Torralba <em>(+1 more)</em></p>
                <p class="paper-abstract" id="abstract-6">Sketching is inherently a sequential process, in which strokes are drawn in a meaningful order to explore and refine ideas. However, most generative models treat sketches as static images,...</p>
                <button class="expand-btn" onclick="toggleAbstract(6, 'Sketching is inherently a sequential process, in which strokes are drawn in a meaningful order to explore and refine ideas. However, most generative models treat sketches as static images, overlooking the temporal structure that underlies creative drawing. We present a data-efficient approach for sequential sketch generation that adapts pretrained text-to-video diffusion models to generate sketching processes. Our key insight is that large language models and video diffusion models offer complementary strengths for this task: LLMs provide semantic planning and stroke ordering, while video diffusion models serve as strong renderers that produce high-quality, temporally coherent visuals. We leverage this by representing sketches as short videos in which strokes are progressively drawn on a blank canvas, guided by text-specified ordering instructions. We introduce a two-stage fine-tuning strategy that decouples the learning of stroke ordering from the learning of sketch appearance. Stroke ordering is learned using synthetic shape compositions with controlled temporal structure, while visual appearance is distilled from as few as seven manually authored sketching processes that capture both global drawing order and the continuous formation of individual strokes. Despite the extremely limited amount of human-drawn sketch data, our method generates high-quality sequential sketches that closely follow text-specified orderings while exhibiting rich visual detail. We further demonstrate the flexibility of our approach through extensions such as brush style conditioning and autoregressive sketch generation, enabling additional controllability and interactive, collaborative drawing.', 'Sketching is inherently a sequential process, in which strokes are drawn in a meaningful order to explore and refine ideas. However, most generative models treat sketches as static images,...')" id="expand-btn-6">Show more â–¼</button>
                <div class="paper-actions">
                    <a href="https://arxiv.org/pdf/2602.15819v1" class="pdf-btn" target="_blank" rel="noopener">ğŸ“„ View PDF</a>
                    <a href="https://arxiv.org/abs/2602.15819v1" class="arxiv-btn" target="_blank" rel="noopener">ğŸ”— arXiv</a>
                </div>
            </article>

            <article class="paper-card" data-search="solving parameter-robust avoid problems with unknown feasibility using reinforcement learning oswin so eric yang yu songyuan zhang matthew cleaveland mitchell black chuchu fan recent advances in deep reinforcement learning (rl) have achieved strong results on high-dimensional control tasks, but applying rl to reachability problems raises a fundamental mismatch: reachability seeks to maximize the set of states from which a system remains safe indefinitely, while rl optimizes expected returns over a user-specified distribution. this mismatch can result in policies that perform poorly on low-probability states that are still within the safe set. a natural alternative is to frame the problem as a robust optimization over a set of initial conditions that specify the initial state, dynamics and safe set, but whether this problem has a solution depends on the feasibility of the specified set, which is unknown a priori. we propose feasibility-guided exploration (fge), a method that simultaneously identifies a subset of feasible initial conditions under which a safe policy exists, and learns a policy to solve the reachability problem over this set of initial conditions. empirical results demonstrate that fge learns policies with over 50% more coverage than the best existing method for challenging initial conditions across tasks in the mujoco simulator and the kinetix simulator with pixel observations.">
                <h2 class="paper-title">
                    <a href="https://arxiv.org/abs/2602.15817v1" target="_blank" rel="noopener">Solving Parameter-Robust Avoid Problems with Unknown Feasibility using Reinforcement Learning</a>
                </h2>
                <div class="paper-meta">
                    <span class="paper-date">ğŸ“… 2026-02-17</span>
                    <span class="paper-category">cs.LG</span><span class="paper-category">cs.RO</span><span class="paper-category">math.OC</span>
                </div>
                <p class="paper-authors">Oswin So, Eric Yang Yu, Songyuan Zhang, Matthew Cleaveland, Mitchell Black <em>(+1 more)</em></p>
                <p class="paper-abstract" id="abstract-7">Recent advances in deep reinforcement learning (RL) have achieved strong results on high-dimensional control tasks, but applying RL to reachability problems raises a fundamental mismatch:...</p>
                <button class="expand-btn" onclick="toggleAbstract(7, 'Recent advances in deep reinforcement learning (RL) have achieved strong results on high-dimensional control tasks, but applying RL to reachability problems raises a fundamental mismatch: reachability seeks to maximize the set of states from which a system remains safe indefinitely, while RL optimizes expected returns over a user-specified distribution. This mismatch can result in policies that perform poorly on low-probability states that are still within the safe set. A natural alternative is to frame the problem as a robust optimization over a set of initial conditions that specify the initial state, dynamics and safe set, but whether this problem has a solution depends on the feasibility of the specified set, which is unknown a priori. We propose Feasibility-Guided Exploration (FGE), a method that simultaneously identifies a subset of feasible initial conditions under which a safe policy exists, and learns a policy to solve the reachability problem over this set of initial conditions. Empirical results demonstrate that FGE learns policies with over 50% more coverage than the best existing method for challenging initial conditions across tasks in the MuJoCo simulator and the Kinetix simulator with pixel observations.', 'Recent advances in deep reinforcement learning (RL) have achieved strong results on high-dimensional control tasks, but applying RL to reachability problems raises a fundamental mismatch:...')" id="expand-btn-7">Show more â–¼</button>
                <div class="paper-actions">
                    <a href="https://arxiv.org/pdf/2602.15817v1" class="pdf-btn" target="_blank" rel="noopener">ğŸ“„ View PDF</a>
                    <a href="https://arxiv.org/abs/2602.15817v1" class="arxiv-btn" target="_blank" rel="noopener">ğŸ”— arXiv</a>
                </div>
            </article>

            <article class="paper-card" data-search="decision quality evaluation framework at pinterest yuqi tian robert paine attila dobi kevin o&#x27;sullivan aravindh manickavasagam faisal farooq online platforms require robust systems to enforce content safety policies at scale. a critical component of these systems is the ability to evaluate the quality of moderation decisions made by both human agents and large language models (llms). however, this evaluation is challenging due to the inherent trade-offs between cost, scale, and trustworthiness, along with the complexity of evolving policies. to address this, we present a comprehensive decision quality evaluation framework developed and deployed at pinterest. the framework is centered on a high-trust golden set (gds) curated by subject matter experts (smes), which serves as a ground truth benchmark. we introduce an automated intelligent sampling pipeline that uses propensity scores to efficiently expand dataset coverage. we demonstrate the framework&#x27;s practical application in several key areas: benchmarking the cost-performance trade-offs of various llm agents, establishing a rigorous methodology for data-driven prompt optimization, managing complex policy evolution, and ensuring the integrity of policy content prevalence metrics via continuous validation. the framework enables a shift from subjective assessments to a data-driven and quantitative practice for managing content safety systems.">
                <h2 class="paper-title">
                    <a href="https://arxiv.org/abs/2602.15809v1" target="_blank" rel="noopener">Decision Quality Evaluation Framework at Pinterest</a>
                </h2>
                <div class="paper-meta">
                    <span class="paper-date">ğŸ“… 2026-02-17</span>
                    <span class="paper-category">stat.AP</span><span class="paper-category">cs.AI</span>
                </div>
                <p class="paper-authors">Yuqi Tian, Robert Paine, Attila Dobi, Kevin O'Sullivan, Aravindh Manickavasagam <em>(+1 more)</em></p>
                <p class="paper-abstract" id="abstract-8">Online platforms require robust systems to enforce content safety policies at scale. A critical component of these systems is the ability to evaluate the quality of moderation decisions made by both...</p>
                <button class="expand-btn" onclick="toggleAbstract(8, 'Online platforms require robust systems to enforce content safety policies at scale. A critical component of these systems is the ability to evaluate the quality of moderation decisions made by both human agents and Large Language Models (LLMs). However, this evaluation is challenging due to the inherent trade-offs between cost, scale, and trustworthiness, along with the complexity of evolving policies. To address this, we present a comprehensive Decision Quality Evaluation Framework developed and deployed at Pinterest. The framework is centered on a high-trust Golden Set (GDS) curated by subject matter experts (SMEs), which serves as a ground truth benchmark. We introduce an automated intelligent sampling pipeline that uses propensity scores to efficiently expand dataset coverage. We demonstrate the framework&#x27;s practical application in several key areas: benchmarking the cost-performance trade-offs of various LLM agents, establishing a rigorous methodology for data-driven prompt optimization, managing complex policy evolution, and ensuring the integrity of policy content prevalence metrics via continuous validation. The framework enables a shift from subjective assessments to a data-driven and quantitative practice for managing content safety systems.', 'Online platforms require robust systems to enforce content safety policies at scale. A critical component of these systems is the ability to evaluate the quality of moderation decisions made by both...')" id="expand-btn-8">Show more â–¼</button>
                <div class="paper-actions">
                    <a href="https://arxiv.org/pdf/2602.15809v1" class="pdf-btn" target="_blank" rel="noopener">ğŸ“„ View PDF</a>
                    <a href="https://arxiv.org/abs/2602.15809v1" class="arxiv-btn" target="_blank" rel="noopener">ğŸ”— arXiv</a>
                </div>
            </article>

            <article class="paper-card" data-search="the geometry of alignment collapse: when fine-tuning breaks safety max springer chung peng lee blossom metevier jane castleman bohdan turbal hayoung jung zeyu shen aleksandra korolova fine-tuning aligned language models on benign tasks unpredictably degrades safety guardrails, even when training data contains no harmful content and developers have no adversarial intent. we show that the prevailing explanation, that fine-tuning updates should be orthogonal to safety-critical directions in high-dimensional parameter space, offers false reassurance: we show this orthogonality is structurally unstable and collapses under the dynamics of gradient descent. we then resolve this through a novel geometric analysis, proving that alignment concentrates in low-dimensional subspaces with sharp curvature, creating a brittle structure that first-order methods cannot detect or defend. while initial fine-tuning updates may indeed avoid these subspaces, the curvature of the fine-tuning loss generates second-order acceleration that systematically steers trajectories into alignment-sensitive regions. we formalize this mechanism through the alignment instability condition, three geometric properties that, when jointly satisfied, lead to safety degradation. our main result establishes a quartic scaling law: alignment loss grows with the fourth power of training time, governed by the sharpness of alignment geometry and the strength of curvature coupling between the fine-tuning task and safety-critical parameters. these results expose a structural blind spot in the current safety paradigm. the dominant approaches to safe fine-tuning address only the initial snapshot of a fundamentally dynamic problem. alignment fragility is not a bug to be patched; it is an intrinsic geometric property of gradient descent on curved manifolds. our results motivate the development of curvature-aware methods, and we hope will further enable a shift in alignment safety analysis from reactive red-teaming to predictive diagnostics for open-weight model deployment.">
                <h2 class="paper-title">
                    <a href="https://arxiv.org/abs/2602.15799v1" target="_blank" rel="noopener">The Geometry of Alignment Collapse: When Fine-Tuning Breaks Safety</a>
                </h2>
                <div class="paper-meta">
                    <span class="paper-date">ğŸ“… 2026-02-17</span>
                    <span class="paper-category">cs.LG</span><span class="paper-category">cs.AI</span>
                </div>
                <p class="paper-authors">Max Springer, Chung Peng Lee, Blossom Metevier, Jane Castleman, Bohdan Turbal <em>(+3 more)</em></p>
                <p class="paper-abstract" id="abstract-9">Fine-tuning aligned language models on benign tasks unpredictably degrades safety guardrails, even when training data contains no harmful content and developers have no adversarial intent. We show...</p>
                <button class="expand-btn" onclick="toggleAbstract(9, 'Fine-tuning aligned language models on benign tasks unpredictably degrades safety guardrails, even when training data contains no harmful content and developers have no adversarial intent. We show that the prevailing explanation, that fine-tuning updates should be orthogonal to safety-critical directions in high-dimensional parameter space, offers false reassurance: we show this orthogonality is structurally unstable and collapses under the dynamics of gradient descent. We then resolve this through a novel geometric analysis, proving that alignment concentrates in low-dimensional subspaces with sharp curvature, creating a brittle structure that first-order methods cannot detect or defend. While initial fine-tuning updates may indeed avoid these subspaces, the curvature of the fine-tuning loss generates second-order acceleration that systematically steers trajectories into alignment-sensitive regions. We formalize this mechanism through the Alignment Instability Condition, three geometric properties that, when jointly satisfied, lead to safety degradation. Our main result establishes a quartic scaling law: alignment loss grows with the fourth power of training time, governed by the sharpness of alignment geometry and the strength of curvature coupling between the fine-tuning task and safety-critical parameters. These results expose a structural blind spot in the current safety paradigm. The dominant approaches to safe fine-tuning address only the initial snapshot of a fundamentally dynamic problem. Alignment fragility is not a bug to be patched; it is an intrinsic geometric property of gradient descent on curved manifolds. Our results motivate the development of curvature-aware methods, and we hope will further enable a shift in alignment safety analysis from reactive red-teaming to predictive diagnostics for open-weight model deployment.', 'Fine-tuning aligned language models on benign tasks unpredictably degrades safety guardrails, even when training data contains no harmful content and developers have no adversarial intent. We show...')" id="expand-btn-9">Show more â–¼</button>
                <div class="paper-actions">
                    <a href="https://arxiv.org/pdf/2602.15799v1" class="pdf-btn" target="_blank" rel="noopener">ğŸ“„ View PDF</a>
                    <a href="https://arxiv.org/abs/2602.15799v1" class="arxiv-btn" target="_blank" rel="noopener">ğŸ”— arXiv</a>
                </div>
            </article>

            <article class="paper-card" data-search="enhancing building semantics preservation in ai model training with large language model encodings suhyung jang ghang lee jaekun lee hyunjun lee accurate representation of building semantics, encompassing both generic object types and specific subtypes, is essential for effective ai model training in the architecture, engineering, construction, and operation (aeco) industry. conventional encoding methods (e.g., one-hot) often fail to convey the nuanced relationships among closely related subtypes, limiting ai&#x27;s semantic comprehension. to address this limitation, this study proposes a novel training approach that employs large language model (llm) embeddings (e.g., openai gpt and meta llama) as encodings to preserve finer distinctions in building semantics. we evaluated the proposed method by training graphsage models to classify 42 building object subtypes across five high-rise residential building information models (bims). various embedding dimensions were tested, including original high-dimensional llm embeddings (1,536, 3,072, or 4,096) and 1,024-dimensional compacted embeddings generated via the matryoshka representation model. experimental results demonstrated that llm encodings outperformed the conventional one-hot baseline, with the llama-3 (compacted) embedding achieving a weighted average f1-score of 0.8766, compared to 0.8475 for one-hot encoding. the results underscore the promise of leveraging llm-based encodings to enhance ai&#x27;s ability to interpret complex, domain-specific building semantics. as the capabilities of llms and dimensionality reduction techniques continue to evolve, this approach holds considerable potential for broad application in semantic elaboration tasks throughout the aeco industry.">
                <h2 class="paper-title">
                    <a href="https://arxiv.org/abs/2602.15791v1" target="_blank" rel="noopener">Enhancing Building Semantics Preservation in AI Model Training with Large Language Model Encodings</a>
                </h2>
                <div class="paper-meta">
                    <span class="paper-date">ğŸ“… 2026-02-17</span>
                    <span class="paper-category">cs.AI</span><span class="paper-category">cs.CL</span>
                </div>
                <p class="paper-authors">Suhyung Jang, Ghang Lee, Jaekun Lee, Hyunjun Lee</p>
                <p class="paper-abstract" id="abstract-10">Accurate representation of building semantics, encompassing both generic object types and specific subtypes, is essential for effective AI model training in the architecture, engineering,...</p>
                <button class="expand-btn" onclick="toggleAbstract(10, 'Accurate representation of building semantics, encompassing both generic object types and specific subtypes, is essential for effective AI model training in the architecture, engineering, construction, and operation (AECO) industry. Conventional encoding methods (e.g., one-hot) often fail to convey the nuanced relationships among closely related subtypes, limiting AI&#x27;s semantic comprehension. To address this limitation, this study proposes a novel training approach that employs large language model (LLM) embeddings (e.g., OpenAI GPT and Meta LLaMA) as encodings to preserve finer distinctions in building semantics. We evaluated the proposed method by training GraphSAGE models to classify 42 building object subtypes across five high-rise residential building information models (BIMs). Various embedding dimensions were tested, including original high-dimensional LLM embeddings (1,536, 3,072, or 4,096) and 1,024-dimensional compacted embeddings generated via the Matryoshka representation model. Experimental results demonstrated that LLM encodings outperformed the conventional one-hot baseline, with the llama-3 (compacted) embedding achieving a weighted average F1-score of 0.8766, compared to 0.8475 for one-hot encoding. The results underscore the promise of leveraging LLM-based encodings to enhance AI&#x27;s ability to interpret complex, domain-specific building semantics. As the capabilities of LLMs and dimensionality reduction techniques continue to evolve, this approach holds considerable potential for broad application in semantic elaboration tasks throughout the AECO industry.', 'Accurate representation of building semantics, encompassing both generic object types and specific subtypes, is essential for effective AI model training in the architecture, engineering,...')" id="expand-btn-10">Show more â–¼</button>
                <div class="paper-actions">
                    <a href="https://arxiv.org/pdf/2602.15791v1" class="pdf-btn" target="_blank" rel="noopener">ğŸ“„ View PDF</a>
                    <a href="https://arxiv.org/abs/2602.15791v1" class="arxiv-btn" target="_blank" rel="noopener">ğŸ”— arXiv</a>
                </div>
            </article>

            <article class="paper-card" data-search="this human study did not involve human subjects: validating llm simulations as behavioral evidence jessica hullman david broska huaman sun aaron shaw a growing literature uses large language models (llms) as synthetic participants to generate cost-effective and nearly instantaneous responses in social science experiments. however, there is limited guidance on when such simulations support valid inference about human behavior. we contrast two strategies for obtaining valid estimates of causal effects and clarify the assumptions under which each is suitable for exploratory versus confirmatory research. heuristic approaches seek to establish that simulated and observed human behavior are interchangeable through prompt engineering, model fine-tuning, and other repair strategies designed to reduce llm-induced inaccuracies. while useful for many exploratory tasks, heuristic approaches lack the formal statistical guarantees typically required for confirmatory research. in contrast, statistical calibration combines auxiliary human data with statistical adjustments to account for discrepancies between observed and simulated responses. under explicit assumptions, statistical calibration preserves validity and provides more precise estimates of causal effects at lower cost than experiments that rely solely on human participants. yet the potential of both approaches depends on how well llms approximate the relevant populations. we consider what opportunities are overlooked when researchers focus myopically on substituting llms for human participants in a study.">
                <h2 class="paper-title">
                    <a href="https://arxiv.org/abs/2602.15785v1" target="_blank" rel="noopener">This human study did not involve human subjects: Validating LLM simulations as behavioral evidence</a>
                </h2>
                <div class="paper-meta">
                    <span class="paper-date">ğŸ“… 2026-02-17</span>
                    <span class="paper-category">cs.AI</span>
                </div>
                <p class="paper-authors">Jessica Hullman, David Broska, Huaman Sun, Aaron Shaw</p>
                <p class="paper-abstract" id="abstract-11">A growing literature uses large language models (LLMs) as synthetic participants to generate cost-effective and nearly instantaneous responses in social science experiments. However, there is limited...</p>
                <button class="expand-btn" onclick="toggleAbstract(11, 'A growing literature uses large language models (LLMs) as synthetic participants to generate cost-effective and nearly instantaneous responses in social science experiments. However, there is limited guidance on when such simulations support valid inference about human behavior. We contrast two strategies for obtaining valid estimates of causal effects and clarify the assumptions under which each is suitable for exploratory versus confirmatory research. Heuristic approaches seek to establish that simulated and observed human behavior are interchangeable through prompt engineering, model fine-tuning, and other repair strategies designed to reduce LLM-induced inaccuracies. While useful for many exploratory tasks, heuristic approaches lack the formal statistical guarantees typically required for confirmatory research. In contrast, statistical calibration combines auxiliary human data with statistical adjustments to account for discrepancies between observed and simulated responses. Under explicit assumptions, statistical calibration preserves validity and provides more precise estimates of causal effects at lower cost than experiments that rely solely on human participants. Yet the potential of both approaches depends on how well LLMs approximate the relevant populations. We consider what opportunities are overlooked when researchers focus myopically on substituting LLMs for human participants in a study.', 'A growing literature uses large language models (LLMs) as synthetic participants to generate cost-effective and nearly instantaneous responses in social science experiments. However, there is limited...')" id="expand-btn-11">Show more â–¼</button>
                <div class="paper-actions">
                    <a href="https://arxiv.org/pdf/2602.15785v1" class="pdf-btn" target="_blank" rel="noopener">ğŸ“„ View PDF</a>
                    <a href="https://arxiv.org/abs/2602.15785v1" class="arxiv-btn" target="_blank" rel="noopener">ğŸ”— arXiv</a>
                </div>
            </article>

            <article class="paper-card" data-search="context-aware skin cancer epithelial cell classification with scalable graph transformers lucas sancÃ©rÃ© noÃ©mie moreau katarzyna bozek whole-slide images (wsis) from cancer patients contain rich information that can be used for medical diagnosis or to follow treatment progress. to automate their analysis, numerous deep learning methods based on convolutional neural networks and vision transformers have been developed and have achieved strong performance in segmentation and classification tasks. however, due to the large size and complex cellular organization of wsis, these models rely on patch-based representations, losing vital tissue-level context. we propose using scalable graph transformers on a full-wsi cell graph for classification. we evaluate this methodology on a challenging task: the classification of healthy versus tumor epithelial cells in cutaneous squamous cell carcinoma (cscc), where both cell types exhibit very similar morphologies and are therefore difficult to differentiate for image-based approaches. we first compared image-based and graph-based methods on a single wsi. graph transformer models sgformer and difformer achieved balanced accuracies of $85.2 \pm 1.5$ ($\pm$ standard error) and $85.1 \pm 2.5$ in 3-fold cross-validation, respectively, whereas the best image-based method reached $81.2 \pm 3.0$. by evaluating several node feature configurations, we found that the most informative representation combined morphological and texture features as well as the cell classes of non-epithelial cells, highlighting the importance of the surrounding cellular context. we then extended our work to train on several wsis from several patients. to address the computational constraints of image-based models, we extracted four $2560 \times 2560$ pixel patches from each image and converted them into graphs. in this setting, difformer achieved a balanced accuracy of $83.6 \pm 1.9$ (3-fold cross-validation), while the state-of-the-art image-based model cellvit256 reached $78.1 \pm 0.5$.">
                <h2 class="paper-title">
                    <a href="https://arxiv.org/abs/2602.15783v1" target="_blank" rel="noopener">Context-aware Skin Cancer Epithelial Cell Classification with Scalable Graph Transformers</a>
                </h2>
                <div class="paper-meta">
                    <span class="paper-date">ğŸ“… 2026-02-17</span>
                    <span class="paper-category">cs.CV</span>
                </div>
                <p class="paper-authors">Lucas SancÃ©rÃ©, NoÃ©mie Moreau, Katarzyna Bozek</p>
                <p class="paper-abstract" id="abstract-12">Whole-slide images (WSIs) from cancer patients contain rich information that can be used for medical diagnosis or to follow treatment progress. To automate their analysis, numerous deep learning...</p>
                <button class="expand-btn" onclick="toggleAbstract(12, 'Whole-slide images (WSIs) from cancer patients contain rich information that can be used for medical diagnosis or to follow treatment progress. To automate their analysis, numerous deep learning methods based on convolutional neural networks and Vision Transformers have been developed and have achieved strong performance in segmentation and classification tasks. However, due to the large size and complex cellular organization of WSIs, these models rely on patch-based representations, losing vital tissue-level context. We propose using scalable Graph Transformers on a full-WSI cell graph for classification. We evaluate this methodology on a challenging task: the classification of healthy versus tumor epithelial cells in cutaneous squamous cell carcinoma (cSCC), where both cell types exhibit very similar morphologies and are therefore difficult to differentiate for image-based approaches. We first compared image-based and graph-based methods on a single WSI. Graph Transformer models SGFormer and DIFFormer achieved balanced accuracies of $85.2 \pm 1.5$ ($\pm$ standard error) and $85.1 \pm 2.5$ in 3-fold cross-validation, respectively, whereas the best image-based method reached $81.2 \pm 3.0$. By evaluating several node feature configurations, we found that the most informative representation combined morphological and texture features as well as the cell classes of non-epithelial cells, highlighting the importance of the surrounding cellular context. We then extended our work to train on several WSIs from several patients. To address the computational constraints of image-based models, we extracted four $2560 \times 2560$ pixel patches from each image and converted them into graphs. In this setting, DIFFormer achieved a balanced accuracy of $83.6 \pm 1.9$ (3-fold cross-validation), while the state-of-the-art image-based model CellViT256 reached $78.1 \pm 0.5$.', 'Whole-slide images (WSIs) from cancer patients contain rich information that can be used for medical diagnosis or to follow treatment progress. To automate their analysis, numerous deep learning...')" id="expand-btn-12">Show more â–¼</button>
                <div class="paper-actions">
                    <a href="https://arxiv.org/pdf/2602.15783v1" class="pdf-btn" target="_blank" rel="noopener">ğŸ“„ View PDF</a>
                    <a href="https://arxiv.org/abs/2602.15783v1" class="arxiv-btn" target="_blank" rel="noopener">ğŸ”— arXiv</a>
                </div>
            </article>

            <article class="paper-card" data-search="neural scaling laws for boosted jet tagging matthias vigl nicole hartman michael kagan lukas heinrich the success of large language models (llms) has established that scaling compute, through joint increases in model capacity and dataset size, is the primary driver of performance in modern machine learning. while machine learning has long been an integral component of high energy physics (hep) data analysis workflows, the compute used to train state-of-the-art hep models remains orders of magnitude below that of industry foundation models. with scaling laws only beginning to be studied in the field, we investigate neural scaling laws for boosted jet classification using the public jetclass dataset. we derive compute optimal scaling laws and identify an effective performance limit that can be consistently approached through increased compute. we study how data repetition, common in hep where simulation is expensive, modifies the scaling yielding a quantifiable effective dataset size gain. we then study how the scaling coefficients and asymptotic performance limits vary with the choice of input features and particle multiplicity, demonstrating that increased compute reliably drives performance toward an asymptotic limit, and that more expressive, lower-level features can raise the performance limit and improve results at fixed dataset size.">
                <h2 class="paper-title">
                    <a href="https://arxiv.org/abs/2602.15781v1" target="_blank" rel="noopener">Neural Scaling Laws for Boosted Jet Tagging</a>
                </h2>
                <div class="paper-meta">
                    <span class="paper-date">ğŸ“… 2026-02-17</span>
                    <span class="paper-category">hep-ex</span><span class="paper-category">cs.LG</span><span class="paper-category">hep-ph</span>
                </div>
                <p class="paper-authors">Matthias Vigl, Nicole Hartman, Michael Kagan, Lukas Heinrich</p>
                <p class="paper-abstract" id="abstract-13">The success of Large Language Models (LLMs) has established that scaling compute, through joint increases in model capacity and dataset size, is the primary driver of performance in modern machine...</p>
                <button class="expand-btn" onclick="toggleAbstract(13, 'The success of Large Language Models (LLMs) has established that scaling compute, through joint increases in model capacity and dataset size, is the primary driver of performance in modern machine learning. While machine learning has long been an integral component of High Energy Physics (HEP) data analysis workflows, the compute used to train state-of-the-art HEP models remains orders of magnitude below that of industry foundation models. With scaling laws only beginning to be studied in the field, we investigate neural scaling laws for boosted jet classification using the public JetClass dataset. We derive compute optimal scaling laws and identify an effective performance limit that can be consistently approached through increased compute. We study how data repetition, common in HEP where simulation is expensive, modifies the scaling yielding a quantifiable effective dataset size gain. We then study how the scaling coefficients and asymptotic performance limits vary with the choice of input features and particle multiplicity, demonstrating that increased compute reliably drives performance toward an asymptotic limit, and that more expressive, lower-level features can raise the performance limit and improve results at fixed dataset size.', 'The success of Large Language Models (LLMs) has established that scaling compute, through joint increases in model capacity and dataset size, is the primary driver of performance in modern machine...')" id="expand-btn-13">Show more â–¼</button>
                <div class="paper-actions">
                    <a href="https://arxiv.org/pdf/2602.15781v1" class="pdf-btn" target="_blank" rel="noopener">ğŸ“„ View PDF</a>
                    <a href="https://arxiv.org/abs/2602.15781v1" class="arxiv-btn" target="_blank" rel="noopener">ğŸ”— arXiv</a>
                </div>
            </article>

            <article class="paper-card" data-search="deep learning for point spread function modeling in cosmology dayana andrea henao arbelÃ¡ez pierre-franÃ§ois lÃ©get andrÃ©s alejandro plazas malagÃ³n we present the development of a data-driven, ai-based model of the point spread function (psf) that achieves higher accuracy than the current state-of-the-art approach, &quot;psf in the full field-of-view&#x27;&#x27; (piff). piff is widely used in leading weak-lensing surveys, including the dark energy survey (des), the hyper suprime-cam (hsc) survey, and the vera c. rubin observatory legacy survey of space and time (lsst). the psf characterizes how a point source, such as a star, is imaged after its light traverses the atmosphere and telescope optics, effectively representing the &quot;blurred fingerprint&#x27;&#x27; of the entire imaging system. accurate psf modeling is essential for weak gravitational lensing analyses, as biases in its estimation propagate directly into cosmic shear measurements -- one of the primary cosmological probes of the expansion history of the universe and the growth of large-scale structure for dark energy studies. to address the limitations of piff, which constructs psf models independently for each ccd and therefore loses spatial coherence across the focal plane, we introduce a deep-learning-based framework for psf reconstruction. in this approach, an autoencoder is trained on stellar images obtained with the hyper suprime-cam (hsc) of the subaru telescope and combined with a gaussian process to interpolate the psf across the telescope&#x27;s full field of view. this hybrid model captures systematic variations across the focal plane and achieves a reconstruction error of $3.4 \times 10^{-6}$ compared to piff&#x27;s $3.7 \times 10^{-6}$, laying the foundation for integration into the lsst science pipelines.">
                <h2 class="paper-title">
                    <a href="https://arxiv.org/abs/2602.15780v1" target="_blank" rel="noopener">Deep Learning for Point Spread Function Modeling in Cosmology</a>
                </h2>
                <div class="paper-meta">
                    <span class="paper-date">ğŸ“… 2026-02-17</span>
                    <span class="paper-category">astro-ph.IM</span><span class="paper-category">astro-ph.CO</span><span class="paper-category">physics.data-an</span>
                </div>
                <p class="paper-authors">Dayana Andrea Henao ArbelÃ¡ez, Pierre-FranÃ§ois LÃ©get, AndrÃ©s Alejandro Plazas MalagÃ³n</p>
                <p class="paper-abstract" id="abstract-14">We present the development of a data-driven, AI-based model of the Point Spread Function (PSF) that achieves higher accuracy than the current state-of-the-art approach, &quot;PSF in the Full...</p>
                <button class="expand-btn" onclick="toggleAbstract(14, 'We present the development of a data-driven, AI-based model of the Point Spread Function (PSF) that achieves higher accuracy than the current state-of-the-art approach, &quot;PSF in the Full Field-of-View&#x27;&#x27; (PIFF). PIFF is widely used in leading weak-lensing surveys, including the Dark Energy Survey (DES), the Hyper Suprime-Cam (HSC) Survey, and the Vera C. Rubin Observatory Legacy Survey of Space and Time (LSST). The PSF characterizes how a point source, such as a star, is imaged after its light traverses the atmosphere and telescope optics, effectively representing the &quot;blurred fingerprint&#x27;&#x27; of the entire imaging system. Accurate PSF modeling is essential for weak gravitational lensing analyses, as biases in its estimation propagate directly into cosmic shear measurements -- one of the primary cosmological probes of the expansion history of the Universe and the growth of large-scale structure for dark energy studies. To address the limitations of PIFF, which constructs PSF models independently for each CCD and therefore loses spatial coherence across the focal plane, we introduce a deep-learning-based framework for PSF reconstruction. In this approach, an autoencoder is trained on stellar images obtained with the Hyper Suprime-Cam (HSC) of the Subaru Telescope and combined with a Gaussian process to interpolate the PSF across the telescope&#x27;s full field of view. This hybrid model captures systematic variations across the focal plane and achieves a reconstruction error of $3.4 \times 10^{-6}$ compared to PIFF&#x27;s $3.7 \times 10^{-6}$, laying the foundation for integration into the LSST Science Pipelines.', 'We present the development of a data-driven, AI-based model of the Point Spread Function (PSF) that achieves higher accuracy than the current state-of-the-art approach, &quot;PSF in the Full...')" id="expand-btn-14">Show more â–¼</button>
                <div class="paper-actions">
                    <a href="https://arxiv.org/pdf/2602.15780v1" class="pdf-btn" target="_blank" rel="noopener">ğŸ“„ View PDF</a>
                    <a href="https://arxiv.org/abs/2602.15780v1" class="arxiv-btn" target="_blank" rel="noopener">ğŸ”— arXiv</a>
                </div>
            </article>

            <article class="paper-card" data-search="vitab-a: evaluating multimodal large language models on visual table attribution yahia alqurnawi preetom biswas anmol rao tejas anvekar chitta baral vivek gupta multimodal large language models (mllms) are often used to answer questions in structured data such as tables in markdown, json, and images. while these models can often give correct answers, users also need to know where those answers come from. in this work, we study structured data attribution/citation, which is the ability of the models to point to the specific rows and columns that support an answer. we evaluate several mllms across different table formats and prompting strategies. our results show a clear gap between question answering and evidence attribution. although question answering accuracy remains moderate, attribution accuracy is much lower, near random for json inputs, across all models. we also find that models are more reliable at citing rows than columns, and struggle more with textual formats than images. finally, we observe notable differences across model families. overall, our findings show that current mllms are unreliable at providing fine-grained, trustworthy attribution for structured data, which limits their usage in applications requiring transparency and traceability.">
                <h2 class="paper-title">
                    <a href="https://arxiv.org/abs/2602.15769v1" target="_blank" rel="noopener">ViTaB-A: Evaluating Multimodal Large Language Models on Visual Table Attribution</a>
                </h2>
                <div class="paper-meta">
                    <span class="paper-date">ğŸ“… 2026-02-17</span>
                    <span class="paper-category">cs.CL</span>
                </div>
                <p class="paper-authors">Yahia Alqurnawi, Preetom Biswas, Anmol Rao, Tejas Anvekar, Chitta Baral <em>(+1 more)</em></p>
                <p class="paper-abstract" id="abstract-15">Multimodal Large Language Models (mLLMs) are often used to answer questions in structured data such as tables in Markdown, JSON, and images. While these models can often give correct answers, users...</p>
                <button class="expand-btn" onclick="toggleAbstract(15, 'Multimodal Large Language Models (mLLMs) are often used to answer questions in structured data such as tables in Markdown, JSON, and images. While these models can often give correct answers, users also need to know where those answers come from. In this work, we study structured data attribution/citation, which is the ability of the models to point to the specific rows and columns that support an answer. We evaluate several mLLMs across different table formats and prompting strategies. Our results show a clear gap between question answering and evidence attribution. Although question answering accuracy remains moderate, attribution accuracy is much lower, near random for JSON inputs, across all models. We also find that models are more reliable at citing rows than columns, and struggle more with textual formats than images. Finally, we observe notable differences across model families. Overall, our findings show that current mLLMs are unreliable at providing fine-grained, trustworthy attribution for structured data, which limits their usage in applications requiring transparency and traceability.', 'Multimodal Large Language Models (mLLMs) are often used to answer questions in structured data such as tables in Markdown, JSON, and images. While these models can often give correct answers, users...')" id="expand-btn-15">Show more â–¼</button>
                <div class="paper-actions">
                    <a href="https://arxiv.org/pdf/2602.15769v1" class="pdf-btn" target="_blank" rel="noopener">ğŸ“„ View PDF</a>
                    <a href="https://arxiv.org/abs/2602.15769v1" class="arxiv-btn" target="_blank" rel="noopener">ğŸ”— arXiv</a>
                </div>
            </article>

            <article class="paper-card" data-search="glm-5: from vibe coding to agentic engineering glm-5 team  : aohan zeng xin lv zhenyu hou zhengxiao du qinkai zheng bin chen da yin chendi ge chengxing xie cunxiang wang gengzheng pan hao zeng haoke zhang haoran wang huilong chen jiajie zhang jian jiao jiaqi guo jingsen wang jingzhao du jinzhu wu kedong wang lei li lin fan lucen zhong mingdao liu mingming zhao pengfan du qian dong rui lu  shuang-li shulin cao song liu ting jiang xiaodong chen xiaohan zhang xuancheng huang xuezhen dong yabo xu yao wei yifan an yilin niu yitong zhu yuanhao wen yukuo cen yushi bai zhongpei qiao zihan wang zikang wang zilin zhu ziqiang liu zixuan li bojie wang bosi wen can huang changpeng cai chao yu chen li chen li chenghua huang chengwei hu chenhui zhang chenzheng zhu congfeng yin daoyan lin dayong yang di wang ding ai erle zhu fangzhou yi feiyu chen guohong wen hailong sun haisha zhao haiyi hu hanchen zhang hanrui liu hanyu zhang hao peng hao tai haobo zhang he liu hongwei wang hongxi yan hongyu ge huan liu huan liu huanpeng chu jia&#x27;ni zhao jiachen wang jiajing zhao jiamin ren jiapeng wang jiaxin zhang jiayi gui jiayue zhao jijie li jing an jing li jingwei yuan jinhua du jinxin liu junkai zhi junwen duan kaiyue zhou kangjian wei ke wang keyun luo laiqiang zhang leigang sha liang xu lindong wu lintao ding lu chen minghao li nianyi lin pan ta qiang zou rongjun song ruiqi yang shangqing tu shangtong yang shaoxiang wu shengyan zhang shijie li shuang li shuyi fan wei qin wei tian weining zhang wenbo yu wenjie liang xiang kuang xiangmeng cheng xiangyang li xiaoquan yan xiaowei hu xiaoying ling xing fan xingye xia xinyuan zhang xinze zhang xirui pan xunkai zhang yandong wu yanfu li yidong wang yifan zhu yijun tan yilin zhou yiming pan ying zhang yinpei su yipeng geng yipeng geng yong yan yonglin tan yuean bi yuhan shen yuhao yang yujiang li yunan liu yunqing wang yuntao li yurong wu yutao zhang yuxi duan yuxuan zhang zezhen liu zhengtao jiang zhenhe yan zheyu zhang zhixiang wei zhuo chen zhuoer feng zijun yao ziwei chai ziyuan wang zuzhou zhang bin xu minlie huang hongning wang juanzi li yuxiao dong jie tang we present glm-5, a next-generation foundation model designed to transition the paradigm of vibe coding to agentic engineering. building upon the agentic, reasoning, and coding (arc) capabilities of its predecessor, glm-5 adopts dsa to significantly reduce training and inference costs while maintaining long-context fidelity. to advance model alignment and autonomy, we implement a new asynchronous reinforcement learning infrastructure that drastically improves post-training efficiency by decoupling generation from training. furthermore, we propose novel asynchronous agent rl algorithms that further improve rl quality, enabling the model to learn from complex, long-horizon interactions more effectively. through these innovations, glm-5 achieves state-of-the-art performance on major open benchmarks. most critically, glm-5 demonstrates unprecedented capability in real-world coding tasks, surpassing previous baselines in handling end-to-end software engineering challenges. code, models, and more information are available at https://github.com/zai-org/glm-5.">
                <h2 class="paper-title">
                    <a href="https://arxiv.org/abs/2602.15763v1" target="_blank" rel="noopener">GLM-5: from Vibe Coding to Agentic Engineering</a>
                </h2>
                <div class="paper-meta">
                    <span class="paper-date">ğŸ“… 2026-02-17</span>
                    <span class="paper-category">cs.LG</span><span class="paper-category">cs.CL</span>
                </div>
                <p class="paper-authors">GLM-5 Team,  :, Aohan Zeng, Xin Lv, Zhenyu Hou <em>(+182 more)</em></p>
                <p class="paper-abstract" id="abstract-16">We present GLM-5, a next-generation foundation model designed to transition the paradigm of vibe coding to agentic engineering. Building upon the agentic, reasoning, and coding (ARC) capabilities of...</p>
                <button class="expand-btn" onclick="toggleAbstract(16, 'We present GLM-5, a next-generation foundation model designed to transition the paradigm of vibe coding to agentic engineering. Building upon the agentic, reasoning, and coding (ARC) capabilities of its predecessor, GLM-5 adopts DSA to significantly reduce training and inference costs while maintaining long-context fidelity. To advance model alignment and autonomy, we implement a new asynchronous reinforcement learning infrastructure that drastically improves post-training efficiency by decoupling generation from training. Furthermore, we propose novel asynchronous agent RL algorithms that further improve RL quality, enabling the model to learn from complex, long-horizon interactions more effectively. Through these innovations, GLM-5 achieves state-of-the-art performance on major open benchmarks. Most critically, GLM-5 demonstrates unprecedented capability in real-world coding tasks, surpassing previous baselines in handling end-to-end software engineering challenges. Code, models, and more information are available at https://github.com/zai-org/GLM-5.', 'We present GLM-5, a next-generation foundation model designed to transition the paradigm of vibe coding to agentic engineering. Building upon the agentic, reasoning, and coding (ARC) capabilities of...')" id="expand-btn-16">Show more â–¼</button>
                <div class="paper-actions">
                    <a href="https://arxiv.org/pdf/2602.15763v1" class="pdf-btn" target="_blank" rel="noopener">ğŸ“„ View PDF</a>
                    <a href="https://arxiv.org/abs/2602.15763v1" class="arxiv-btn" target="_blank" rel="noopener">ğŸ”— arXiv</a>
                </div>
            </article>

            <article class="paper-card" data-search="a differential fuzzing-based evaluation of functional equivalence in llm-generated code refactorings simantika bhattacharjee dristi matthew b. dwyer with the rapid adoption of large language models (llms) in automated code refactoring, assessing and ensuring functional equivalence between llm-generated refactoring and the original implementation becomes critical. while prior work typically relies on predefined test cases to evaluate correctness, in this work, we leverage differential fuzzing to check functional equivalence in llm-generated code refactorings. unlike test-based evaluation, a differential fuzzing-based equivalence checker needs no predefined test cases and can explore a much larger input space by executing and comparing thousands of automatically generated test inputs. in a large-scale evaluation of six llms (codellama, codestral, starchat2, qwen-2.5, olmo-3, and gpt-4o) across three datasets and two refactoring types, we find that llms show a non-trivial tendency to alter program semantics, producing 19-35% functionally non-equivalent refactorings. our experiments further demonstrate that about 21% of these non-equivalent refactorings remain undetected by the existing test suites of the three evaluated datasets. collectively, the findings of this study imply that reliance on existing tests might overestimate functional equivalence in llm-generated code refactorings, which remain prone to semantic divergence.">
                <h2 class="paper-title">
                    <a href="https://arxiv.org/abs/2602.15761v1" target="_blank" rel="noopener">A Differential Fuzzing-Based Evaluation of Functional Equivalence in LLM-Generated Code Refactorings</a>
                </h2>
                <div class="paper-meta">
                    <span class="paper-date">ğŸ“… 2026-02-17</span>
                    <span class="paper-category">cs.SE</span>
                </div>
                <p class="paper-authors">Simantika Bhattacharjee Dristi, Matthew B. Dwyer</p>
                <p class="paper-abstract" id="abstract-17">With the rapid adoption of large language models (LLMs) in automated code refactoring, assessing and ensuring functional equivalence between LLM-generated refactoring and the original implementation...</p>
                <button class="expand-btn" onclick="toggleAbstract(17, 'With the rapid adoption of large language models (LLMs) in automated code refactoring, assessing and ensuring functional equivalence between LLM-generated refactoring and the original implementation becomes critical. While prior work typically relies on predefined test cases to evaluate correctness, in this work, we leverage differential fuzzing to check functional equivalence in LLM-generated code refactorings. Unlike test-based evaluation, a differential fuzzing-based equivalence checker needs no predefined test cases and can explore a much larger input space by executing and comparing thousands of automatically generated test inputs. In a large-scale evaluation of six LLMs (CodeLlama, Codestral, StarChat2, Qwen-2.5, Olmo-3, and GPT-4o) across three datasets and two refactoring types, we find that LLMs show a non-trivial tendency to alter program semantics, producing 19-35% functionally non-equivalent refactorings. Our experiments further demonstrate that about 21% of these non-equivalent refactorings remain undetected by the existing test suites of the three evaluated datasets. Collectively, the findings of this study imply that reliance on existing tests might overestimate functional equivalence in LLM-generated code refactorings, which remain prone to semantic divergence.', 'With the rapid adoption of large language models (LLMs) in automated code refactoring, assessing and ensuring functional equivalence between LLM-generated refactoring and the original implementation...')" id="expand-btn-17">Show more â–¼</button>
                <div class="paper-actions">
                    <a href="https://arxiv.org/pdf/2602.15761v1" class="pdf-btn" target="_blank" rel="noopener">ğŸ“„ View PDF</a>
                    <a href="https://arxiv.org/abs/2602.15761v1" class="arxiv-btn" target="_blank" rel="noopener">ğŸ”— arXiv</a>
                </div>
            </article>

            <article class="paper-card" data-search="charteditbench: evaluating grounded multi-turn chart editing in multimodal language models manav nitin kapadnis lawanya baghel atharva naik carolyn rosÃ© while multimodal large language models (mllms) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. in practice, users iteratively refine visualizations through multi-turn interactions that require maintaining common ground, tracking prior edits, and adapting to evolving preferences. we introduce charteditbench, a benchmark for incremental, visually grounded chart editing via code, comprising 5,000 difficulty-controlled modification chains and a rigorously human-verified subset. unlike prior one-shot benchmarks, charteditbench evaluates sustained, context-aware editing. we further propose a robust evaluation framework that mitigates limitations of llm-as-a-judge metrics by integrating execution-based fidelity checks, pixel-level visual similarity, and logical code verification. experiments with state-of-the-art mllms reveal substantial degradation in multi-turn settings due to error accumulation and breakdowns in shared context, with strong performance on stylistic edits but frequent execution failures on data-centric transformations. charteditbench, establishes a challenging testbed for grounded, intent-aware multimodal programming.">
                <h2 class="paper-title">
                    <a href="https://arxiv.org/abs/2602.15758v1" target="_blank" rel="noopener">ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="paper-date">ğŸ“… 2026-02-17</span>
                    <span class="paper-category">cs.CL</span><span class="paper-category">cs.AI</span>
                </div>
                <p class="paper-authors">Manav Nitin Kapadnis, Lawanya Baghel, Atharva Naik, Carolyn RosÃ©</p>
                <p class="paper-abstract" id="abstract-18">While Multimodal Large Language Models (MLLMs) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. In practice,...</p>
                <button class="expand-btn" onclick="toggleAbstract(18, 'While Multimodal Large Language Models (MLLMs) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. In practice, users iteratively refine visualizations through multi-turn interactions that require maintaining common ground, tracking prior edits, and adapting to evolving preferences. We introduce ChartEditBench, a benchmark for incremental, visually grounded chart editing via code, comprising 5,000 difficulty-controlled modification chains and a rigorously human-verified subset. Unlike prior one-shot benchmarks, ChartEditBench evaluates sustained, context-aware editing. We further propose a robust evaluation framework that mitigates limitations of LLM-as-a-Judge metrics by integrating execution-based fidelity checks, pixel-level visual similarity, and logical code verification. Experiments with state-of-the-art MLLMs reveal substantial degradation in multi-turn settings due to error accumulation and breakdowns in shared context, with strong performance on stylistic edits but frequent execution failures on data-centric transformations. ChartEditBench, establishes a challenging testbed for grounded, intent-aware multimodal programming.', 'While Multimodal Large Language Models (MLLMs) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. In practice,...')" id="expand-btn-18">Show more â–¼</button>
                <div class="paper-actions">
                    <a href="https://arxiv.org/pdf/2602.15758v1" class="pdf-btn" target="_blank" rel="noopener">ğŸ“„ View PDF</a>
                    <a href="https://arxiv.org/abs/2602.15758v1" class="arxiv-btn" target="_blank" rel="noopener">ğŸ”— arXiv</a>
                </div>
            </article>

            <article class="paper-card" data-search="a note on non-composability of layerwise approximate verification for neural inference or zamir a natural and informal approach to verifiable (or zero-knowledge) ml inference over floating-point data is: ``prove that each layer was computed correctly up to tolerance $Î´$; therefore the final output is a reasonable inference result&#x27;&#x27;. this short note gives a simple counterexample showing that this inference is false in general: for any neural network, we can construct a functionally equivalent network for which adversarially chosen approximation-magnitude errors in individual layer computations suffice to steer the final output arbitrarily (within a prescribed bounded range).">
                <h2 class="paper-title">
                    <a href="https://arxiv.org/abs/2602.15756v1" target="_blank" rel="noopener">A Note on Non-Composability of Layerwise Approximate Verification for Neural Inference</a>
                </h2>
                <div class="paper-meta">
                    <span class="paper-date">ğŸ“… 2026-02-17</span>
                    <span class="paper-category">cs.CR</span><span class="paper-category">cs.LG</span>
                </div>
                <p class="paper-authors">Or Zamir</p>
                <p class="paper-abstract" id="abstract-19">A natural and informal approach to verifiable (or zero-knowledge) ML inference over floating-point data is: ``prove that each layer was computed correctly up to tolerance $Î´$; therefore the final...</p>
                <button class="expand-btn" onclick="toggleAbstract(19, 'A natural and informal approach to verifiable (or zero-knowledge) ML inference over floating-point data is: ``prove that each layer was computed correctly up to tolerance $Î´$; therefore the final output is a reasonable inference result&#x27;&#x27;. This short note gives a simple counterexample showing that this inference is false in general: for any neural network, we can construct a functionally equivalent network for which adversarially chosen approximation-magnitude errors in individual layer computations suffice to steer the final output arbitrarily (within a prescribed bounded range).', 'A natural and informal approach to verifiable (or zero-knowledge) ML inference over floating-point data is: ``prove that each layer was computed correctly up to tolerance $Î´$; therefore the final...')" id="expand-btn-19">Show more â–¼</button>
                <div class="paper-actions">
                    <a href="https://arxiv.org/pdf/2602.15756v1" class="pdf-btn" target="_blank" rel="noopener">ğŸ“„ View PDF</a>
                    <a href="https://arxiv.org/abs/2602.15756v1" class="arxiv-btn" target="_blank" rel="noopener">ğŸ”— arXiv</a>
                </div>
            </article>

        </div>
    </div>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>&copy; 2026 Coding Blog | BST 236 Computing I | Harvard University</p>
            <p class="footer-links">
                <a href="https://github.com">GitHub</a>
            </p>
        </div>
    </footer>

    <script src="js/main.js"></script>
    <script>
        function filterPapers() {
            const query = document.getElementById('searchInput').value.toLowerCase();
            const cards = document.querySelectorAll('.paper-card');
            
            cards.forEach(card => {
                const searchText = card.getAttribute('data-search');
                if (searchText.includes(query)) {
                    card.classList.remove('hidden');
                } else {
                    card.classList.add('hidden');
                }
            });
        }
        
        function toggleAbstract(index, fullText, shortText) {
            const abstractEl = document.getElementById('abstract-' + index);
            const btnEl = document.getElementById('expand-btn-' + index);
            
            if (abstractEl.classList.contains('expanded')) {
                abstractEl.textContent = shortText;
                abstractEl.classList.remove('expanded');
                btnEl.textContent = 'Show more â–¼';
            } else {
                abstractEl.textContent = fullText;
                abstractEl.classList.add('expanded');
                btnEl.textContent = 'Show less â–²';
            }
        }
        
        // Client-side arXiv fetching for custom keywords
        // CORS proxies to try in order
        const corsProxies = [
            url => `https://corsproxy.io/?${encodeURIComponent(url)}`,
            url => `https://api.codetabs.com/v1/proxy?quest=${encodeURIComponent(url)}`,
            url => `https://api.allorigins.win/raw?url=${encodeURIComponent(url)}`
        ];
        
        async function tryFetchWithProxies(url, proxies) {
            for (let i = 0; i < proxies.length; i++) {
                const proxyUrl = proxies[i](url);
                try {
                    const response = await fetch(proxyUrl, { timeout: 10000 });
                    if (response.ok) {
                        return await response.text();
                    }
                } catch (e) {
                    console.log(`Proxy ${i + 1} failed:`, e.message);
                }
            }
            throw new Error('All CORS proxies failed. Please try again later or edit scripts/config.json directly.');
        }
        
        async function fetchCustomPapers() {
            const input = document.getElementById('customKeywords').value.trim();
            const btn = document.getElementById('fetchBtn');
            const grid = document.getElementById('papersGrid');
            const keywordsDisplay = document.getElementById('currentKeywords');
            
            if (!input) {
                alert('Please enter at least one keyword');
                return;
            }
            
            const keywords = input.split(',').map(k => k.trim()).filter(k => k);
            
            btn.disabled = true;
            btn.textContent = 'Fetching...';
            
            // Update displayed keywords
            keywordsDisplay.innerHTML = keywords.map(kw => 
                `<span class="keyword-tag">${escapeHtml(kw)}</span>`
            ).join('');
            
            // Build arXiv query
            const searchQuery = keywords.map(kw => `all:"${kw}"`).join(' OR ');
            const url = `https://export.arxiv.org/api/query?search_query=${encodeURIComponent(searchQuery)}&start=0&max_results=20&sortBy=submittedDate&sortOrder=descending`;
            
            try {
                const xmlText = await tryFetchWithProxies(url, corsProxies);
                
                // Parse XML
                const parser = new DOMParser();
                const xmlDoc = parser.parseFromString(xmlText, 'text/xml');
                const entries = xmlDoc.querySelectorAll('entry');
                
                if (entries.length === 0) {
                    grid.innerHTML = `
                        <div class="no-results" style="grid-column: 1 / -1;">
                            <h3>No papers found</h3>
                            <p>Try different keywords.</p>
                        </div>
                    `;
                } else {
                    let html = '';
                    entries.forEach((entry, i) => {
                        const title = entry.querySelector('title')?.textContent?.replace(/\s+/g, ' ').trim() || 'Untitled';
                        const abstract = entry.querySelector('summary')?.textContent?.replace(/\s+/g, ' ').trim() || 'No abstract';
                        const published = entry.querySelector('published')?.textContent?.substring(0, 10) || 'Unknown';
                        const id = entry.querySelector('id')?.textContent || '';
                        const pdfUrl = id.replace('/abs/', '/pdf/') + '.pdf';
                        
                        const authors = [];
                        entry.querySelectorAll('author name').forEach(n => authors.push(n.textContent));
                        const authorsStr = authors.length > 5 
                            ? authors.slice(0, 5).join(', ') + ` <em>(+${authors.length - 5} more)</em>`
                            : authors.join(', ');
                        
                        const categories = [];
                        entry.querySelectorAll('category').forEach(c => {
                            const term = c.getAttribute('term');
                            if (term && categories.length < 3) categories.push(term);
                        });
                        
                        const abstractShort = abstract.length > 200 
                            ? abstract.substring(0, 200).replace(/\s+\S*$/, '') + '...'
                            : abstract;
                        
                        html += `
                            <article class="paper-card" data-search="${escapeHtml(title.toLowerCase())} ${escapeHtml(authors.join(' ').toLowerCase())} ${escapeHtml(abstract.toLowerCase())}">
                                <h2 class="paper-title">
                                    <a href="${escapeHtml(id)}" target="_blank" rel="noopener">${escapeHtml(title)}</a>
                                </h2>
                                <div class="paper-meta">
                                    <span class="paper-date">ğŸ“… ${escapeHtml(published)}</span>
                                    ${categories.map(c => `<span class="paper-category">${escapeHtml(c)}</span>`).join('')}
                                </div>
                                <p class="paper-authors">${authorsStr}</p>
                                <p class="paper-abstract" id="abstract-dyn-${i}">${escapeHtml(abstractShort)}</p>
                                <button class="expand-btn" onclick="toggleAbstract('dyn-${i}', '${escapeHtml(abstract).replace(/'/g, "\\'")}', '${escapeHtml(abstractShort).replace(/'/g, "\\'")}')">Show more â–¼</button>
                                <div class="paper-actions">
                                    <a href="${escapeHtml(pdfUrl)}" class="pdf-btn" target="_blank" rel="noopener">ğŸ“„ View PDF</a>
                                    <a href="${escapeHtml(id)}" class="arxiv-btn" target="_blank" rel="noopener">ğŸ”— arXiv</a>
                                </div>
                            </article>
                        `;
                    });
                    grid.innerHTML = html;
                }
                
                // Update timestamp
                const now = new Date().toISOString().replace('T', ' ').substring(0, 19) + ' (live fetch)';
                document.querySelector('.update-info').textContent = 'Last updated: ' + now;
                
            } catch (error) {
                console.error('Fetch error:', error);
                grid.innerHTML = `
                    <div class="no-results" style="grid-column: 1 / -1;">
                        <h3>Error fetching papers</h3>
                        <p>${escapeHtml(error.message)}</p>
                        <p style="margin-top: 15px; font-size: 0.9rem;">
                            <strong>Alternative:</strong> Edit <code style="background: #334155; padding: 2px 6px; border-radius: 4px;">scripts/config.json</code> 
                            and run <code style="background: #334155; padding: 2px 6px; border-radius: 4px;">python scripts/fetch_arxiv.py</code> locally, 
                            or push to GitHub to trigger the auto-update.
                        </p>
                    </div>
                `;
            }
            
            btn.disabled = false;
            btn.textContent = 'Fetch Papers';
        }
        
        function escapeHtml(text) {
            const div = document.createElement('div');
            div.textContent = text;
            return div.innerHTML;
        }
        
        // Allow Enter key to trigger fetch
        document.getElementById('customKeywords').addEventListener('keypress', function(e) {
            if (e.key === 'Enter') fetchCustomPapers();
        });
    </script>
</body>
</html>
